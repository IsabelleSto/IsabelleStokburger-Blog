[
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Die Klassifikation von Hate Speech mit R in der Version 4.3.1 bietet eine effiziente Methode, um digitale Kommunikation auf toxische Inhalte zu analysieren. Das Stastikprogramm R eignet sich gut zur Verarbeitung natürlicher Sprache und maschinellen Lernen, um Hate Speech in Textdaten zu identifizieren und zu kategorisieren. Im Folgenden werden mit Hilfe verschiedener Textmining Methoden Tweets auf Hate Speech hin untersucht. Darüber hinaus werden prädiktive Modelle zur Klassifikation von Hate-Speech angewandt."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#daten-laden",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#daten-laden",
    "title": "Hate Speech Klassifikation",
    "section": "2.1 Daten laden",
    "text": "2.1 Daten laden\n\nd_hate&lt;-\n  read.csv(datenpfad)\n\n\n2.1.1 Pakete laden\n\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(beepr)\nlibrary(discrim)\nlibrary(naivebayes)\nlibrary(textrecipes) \nlibrary(syuzhet)\nlibrary(tokenizers)  # Tokenisieren\nlibrary(tidytext)  # Textanalyse-Tools\nlibrary(SnowballC)  # Stemming\nlibrary(lsa)  # Stopwörter\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`\nlibrary(textclean)  # Emojis ersetzen\nlibrary(wordcloud)  # unübersichtlich, aber manche mögen es\nlibrary(ggplot2)\n\n\nd_hate1&lt;-\n  d_hate%&gt;%\n  select(tweet, class)%&gt;%\n  mutate(id = as.character(1:nrow(.)))\n\nd_hate1%&gt;%\n  count(class)\n\n\n\n  \n\n\n# Anzahl der Tweets pro Klasse zählen\nclass_counts &lt;- d_hate1 %&gt;%\n  count(class)\n\n# Histogramm erstellen\nggplot(class_counts, aes(x = class, y = n, fill = class)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  scale_fill_manual(values = c(\"hatespeech\" = \"yellow\", \"other\" = \"cyan\")) +\n  labs(title = \"Verteilung der Tweets nach Klasse\",\n       x = \"Klasse\",\n       y = \"Anzahl der Tweets\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nDas Balkendiagramm zeigt die Verteilung der Tweet in den zwei Klassen “hate_speech” und “other”. Rund 25% der Tweets sind im Datensatz als Hate Speech gelabelt."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#bestes-modell-extrahieren",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#bestes-modell-extrahieren",
    "title": "Hate Speech Klassifikation",
    "section": "6.3 Bestes Modell extrahieren",
    "text": "6.3 Bestes Modell extrahieren\n\nbest_ml &lt;- \n  extract_workflow_set_result(results, \"text_prep_rf\") %&gt;% \n  select_best()\n\nbest_wf &lt;- \nwf_set %&gt;% \n  extract_workflow(\"text_prep_rf\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_ml)\n\nfit_final &lt;- fit(best_wf_finalized, data = d_train)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IsabelleStokburger Blog",
    "section": "",
    "text": "Hate Speech Klassifikation\n\n\n\n\n\n\n\nTextanalyse\n\n\nTidymodels\n\n\nKlassifikation\n\n\nTransformers\n\n\nNeuronale Netze\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nIsabelle Stokburger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#aufteilung-in-test--und-traindatensatz",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#aufteilung-in-test--und-traindatensatz",
    "title": "Hate Speech Klassifikation",
    "section": "3.1 Aufteilung in Test- und Traindatensatz",
    "text": "3.1 Aufteilung in Test- und Traindatensatz\n\nset.seed(123)\nd_split &lt;- initial_split(d_hate1, prop = .8, strata = class)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n3.1.1 Seiten und Wörter zählen\n\nstr_count(d_train$tweet, pattern = \"\\\\w\") %&gt;% sum(na.rm = TRUE)\n\n[1] 295528\n\n\nDie zu untersuchende Zeile “Tweet” enthält 36.9224 Wörter. Das ist eine ausreichende Menge, um ein Modell sinnvoll trainieren zu können.\n\nNachstehend werden verschiedene Textmerkmale, auch als Textfeatures bezeichnet, untersucht. Durch das Analysieren der spezifischen Eigenschaften können Informationen über den Inhalt, die Struktur und die Bedeutung der Tweets gewonnen werden. Das hilft dabei, im späteren Verlauf Hassrede zu identifizieren. Anschließend werden die Tweets auf * Wortfrequenzen * Schimpfwörter * Emotionale Ladung untersucht."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#tokenisierung",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#tokenisierung",
    "title": "Hate Speech Klassifikation",
    "section": "3.2 Tokenisierung",
    "text": "3.2 Tokenisierung\n\ntokens &lt;- d_train %&gt;%\n  unnest_tokens(word, tweet)\n\nDie Tokenisierung stellt einen wichtigen Schritt in der Textverarbeitung dar. Sie teilt den Text in sinnvolle Einheiten, sogenannte Tokens auf. Erst das ermöglicht weitere Verarbeitungsschritte, wie beispielsweise die Stoppwordentfernung."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#entfernen-von-stopwords",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#entfernen-von-stopwords",
    "title": "Hate Speech Klassifikation",
    "section": "3.3 Entfernen von Stopwords",
    "text": "3.3 Entfernen von Stopwords\n\n3.3.1 Stopwords für deutsch & englisch laden und kombinieren\n\ndata(stopwords_de, package = \"lsa\")\ndata(stopwords_en, package = \"lsa\")\nstopwords_en &lt;- tibble(word = stopwords_en)\nstopwords_de &lt;- tibble(word = stopwords_de)\nstopwords &lt;- bind_rows(stopwords_de, stopwords_en)\n\n\ntokens_filtered &lt;- tokens %&gt;%\n  anti_join(stopwords, by = \"word\")\n\nDas Entfernen von stopwords hat den Vorteil, dass durch das Entfernen häufig vorkommende Wörter ohne semantische Bedeutung wie “a”, “and”, “so”… Rauschen im Text reduziert und die Analysequalität verbessert wird. Darüber hinaus verringert sich die zu verarbeitende Datenmenge."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#textlänge",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#textlänge",
    "title": "Hate Speech Klassifikation",
    "section": "3.4 Textlänge",
    "text": "3.4 Textlänge\n\ntext_length &lt;- tokens_filtered %&gt;%\n  group_by(id) %&gt;%\n  summarise(word_count = n())\n\nDie Textlänge kann Aufschluss über die Menge und Vielfalt der Informationen der Tweets geben. Gibt es möglicherweisee ungewöhnliche kurze oder lange Tweets, die genauer betrachtet werden sollten?"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#worthäufigkeit",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#worthäufigkeit",
    "title": "Hate Speech Klassifikation",
    "section": "3.5 Worthäufigkeit",
    "text": "3.5 Worthäufigkeit\n\nword_freq &lt;- tokens_filtered %&gt;%\n  count(word, sort = TRUE)\n\nprint(head(text_length, n = 20)) # Die Textlänge der ersten 10 Tweets\n\n# A tibble: 20 × 2\n   id    word_count\n   &lt;chr&gt;      &lt;int&gt;\n 1 1              9\n 2 100           15\n 3 1001           4\n 4 1002           5\n 5 1003           5\n 6 1005           3\n 7 1006          11\n 8 1007          10\n 9 1009           4\n10 101            9\n11 1010          12\n12 1011           6\n13 1012           3\n14 1013           6\n15 1014           7\n16 1015          10\n17 1016           6\n18 1017           6\n19 1018           9\n20 1019           6\n\nprint(head(word_freq, n = 20))   # Die 10 häufigsten Wörter\n\n      word    n\n1       rt 1327\n2    trash  642\n3     bird  238\n4  yankees  234\n5  charlie  229\n6      i'm  193\n7      amp  182\n8    don't  181\n9   yellow  180\n10   bitch  170\n11    it's  167\n12     lol  158\n13  faggot  157\n14   white  142\n15   birds  139\n16     ass  112\n17  people  112\n18   nigga  108\n19 colored  107\n20  ghetto  104\n\n#Berechnung der Wortfrequenz\nword_freq_filtered &lt;- tokens_filtered %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(20, n)\n\n\n3.5.1 Visualisierung der Textlänge\n\ntext_length_filtered &lt;- tokens_filtered %&gt;%\n  group_by(id) %&gt;%\n  summarise(word_count = n())\n\n# Aktualisierte Visualisierung: Histogramm der Textlänge ohne Stoppwörter\nggplot(text_length_filtered, aes(x = word_count)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"white\") +\n  theme_minimal() +\n  labs(title = \"Histogramm der Textlänge ohne Stoppwörter\", x = \"Anzahl der Wörter pro Tweet\", y = \"Häufigkeit\")\n\n\n\n\nDie Tweets bewegen sich alle in einem ähnlichen Rahmen und sind i.d.R zwischen drei und 13 Wörtern lang."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-1-barplot-der-häufigsten-wörter-ohne-stopwords",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-1-barplot-der-häufigsten-wörter-ohne-stopwords",
    "title": "Hate Speech Klassifikation",
    "section": "3.6 Visualisierung 1: Barplot der häufigsten Wörter ohne Stopwords",
    "text": "3.6 Visualisierung 1: Barplot der häufigsten Wörter ohne Stopwords\n\nggplot(word_freq_filtered, aes(x = reorder(word, n), y = n)) +\n  geom_col(fill = \"coral\", color = \"white\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Top 20 häufigste Wörter\", x = \"\", y = \"Häufigkeit\")\n\n\n\n\nAllein unter den 20 häufigsten Wörtern befinden sich bereits sieben Schimpfwörter. Die Genauigkeit der Grafik könnte noch verbessert werden, indem zum Beispiel ähnliche Ausdrücke wie “nigga” und “nigger” zusammengefasst werden, sodass der Barplot die kummulierte Häufigkeit anzeigt. Zusätzlich könnten weitere stopwords wie “it” durch die Hinzunahme eines weiteren Stopwords-Datensatzes entfernt werden.\n\n3.6.1 Wörter ohne Aussagekraft aus tokenisierten Daten entfernen\n\ntokens_filtered &lt;- tokens_filtered %&gt;%\n  filter(word != \"rt\")\n\nDa der Ausdruck “rt” keine Aussagekraft hat, wird er aus dem Datensatz entfernt.\n\n#Sentimentanalyse\n\nsenti_afinn &lt;- get_sentiments(\"afinn\") %&gt;% \n  mutate(neg_pos = case_when(value &gt; 0 ~ \"pos\",\n                             TRUE ~ \"neg\"))\n\n# Sentimentanalyse durchführen\ntokens_senti &lt;- tokens_filtered %&gt;%\n  inner_join(senti_afinn, by = \"word\")\n\nEin ebenfalls sehr wichtiges Werkzeug zur Datenanalyse ist die Sentimentanalyse. Mit ihr kann festgestellt werden, ob unsere Tweets bzw. Tokens eine negative oder positive Polung aufweisen, wobei Hate Speech mit einer negativen einhergeht. Die Textdaten werden so gefiltert, dass nur Wörter mit Sentimentwerten übrig bleiben."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#berechnung-der-durchschnittlichen-sentimentwerte-pro-polarität-und-tweet",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#berechnung-der-durchschnittlichen-sentimentwerte-pro-polarität-und-tweet",
    "title": "Hate Speech Klassifikation",
    "section": "3.7 Berechnung der durchschnittlichen Sentimentwerte pro Polarität und Tweet",
    "text": "3.7 Berechnung der durchschnittlichen Sentimentwerte pro Polarität und Tweet\n\ntokens_senti2 &lt;-\n  tokens_senti %&gt;% \n  group_by(id, neg_pos) %&gt;% \n  summarise(senti_avg = mean(value))\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\nhead(tokens_senti2)"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#zusammenführung-der-sentimentwerte-und-textlänge-in-den-hauptdatensatz",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#zusammenführung-der-sentimentwerte-und-textlänge-in-den-hauptdatensatz",
    "title": "Hate Speech Klassifikation",
    "section": "3.8 Zusammenführung der Sentimentwerte und Textlänge in den Hauptdatensatz",
    "text": "3.8 Zusammenführung der Sentimentwerte und Textlänge in den Hauptdatensatz\n\nsentis_wide &lt;-\n  tokens_senti2 %&gt;% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"senti_avg\")\n\nsentis_wide %&gt;% head()\n\n\n\n  \n\n\n#Zusammenführung mit Ursprungsdatensatz\nd_train2&lt;-\n  d_train%&gt;%\n  full_join(sentis_wide)\n\nJoining with `by = join_by(id)`\n\nd_train2 &lt;- d_train2 %&gt;%\n  left_join(text_length, by = \"id\")\n\n\nsenti_afinn%&gt;%\n  select(value, neg_pos)%&gt;%\n  describe_distribution()\n\n\n\n  \n\n\ntokens_senti %&gt;% \n  summarise(senti_sum = mean(value) %&gt;% round(2))\n\n\n\n  \n\n\n\nDas Sentimentlexikon ist insgesamt mit einem Wert von -0.59 leicht negativ. Die Tweets liegen mit -1.01 deutlich im negativen Bereich."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-der-sentimentanalyse",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-der-sentimentanalyse",
    "title": "Hate Speech Klassifikation",
    "section": "3.9 Visualisierung der Sentimentanalyse",
    "text": "3.9 Visualisierung der Sentimentanalyse\n\nlibrary(ggplot2)\n\ntokens_senti %&gt;%\n  count(word, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(n, word, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Wort\") +\n  theme_minimal()\n\n\n\n\nAuffällig ist, dass die negativ behafteten Wörter insgesamt deutlich häufiger vorkommen, als die positiven. Wenigsten wird der Ausdruck “love” häufiger verwendet als “hate."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-der-bigramme",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung-der-bigramme",
    "title": "Hate Speech Klassifikation",
    "section": "4.1 Visualisierung der Bigramme",
    "text": "4.1 Visualisierung der Bigramme\n\n# Visualisierung der Top-Bigramme\nggplot(top_bigrams, aes(x = reorder(bigram, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 häufigste Bigramme\",\n       x = \"Bigramme\",\n       y = \"Häufigkeit\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#stemming",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#stemming",
    "title": "Hate Speech Klassifikation",
    "section": "4.2 Stemming",
    "text": "4.2 Stemming\n\n# Stemming\ntokens_filtered$word &lt;- wordStem(tokens_filtered$word, language = \"en\")\n\n# Häufigkeiten zählen\nword_freq_stem &lt;- tokens_filtered %&gt;%\n  count(word, sort = TRUE)\n\n# Die 10 häufigsten Wörter auswählen\ntop_words_stem &lt;- head(word_freq_stem, 10)\n\n# Visualisierung\nggplot(top_words_stem, aes(x = reorder(word, n), y = n, fill = word)) +\n  geom_col() +\n  coord_flip() +  # Um die Wörter horizontal anzuzeigen\n  labs(title = \"Top 10 gestemmte Wörter\", x = \"Wörter\", y = \"Häufigkeit\") +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\nGroße Aussagekraft hat das nicht und neue Erkenntnisse kann ich daraus nicht ziehen. Zumindest ist es bunt und hebt die Stimmung für weiter Analysen\n\ncomms_bigram &lt;- \n  d_train2 %&gt;%\n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\ncomms_bigram &lt;- comms_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ncomms_bigram %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(title = \"Bigramme nach Häufigkeit\",\n       x = \"Häufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#rezept",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#rezept",
    "title": "Hate Speech Klassifikation",
    "section": "6.1 Rezept",
    "text": "6.1 Rezept\nDas Rezept enthält die Textlänge, Sentimentwerte, Schimpfwörter und tfidf.\n\nlibrary(syuzhet)\n\nrec1 &lt;-\n  recipe(class ~ ., data = d_train) %&gt;%\n  update_role(id, new_role = \"id\") %&gt;% \n  step_text_normalization(tweet) %&gt;%\n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\") %&gt;%\n  step_stem(tweet) %&gt;%  \n  step_tfidf(tweet)\n \n  # step_mutate(senti = get_sentiment(tweet))\n\n#step_mutate(insult = get_sentiment(tweet,\n                                       #method = \"custom\",\n                                       #lexicon = insults)) %&gt;% \n\n\nbaked &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked\n\n\n\n  \n\n\n\nModell\n\nlm &lt;- naive_Bayes() %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"naivebayes\")\nlm\n\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\nKreuzvalidierung\n\nset.seed(42)\nfolds1 &lt;- vfold_cv(d_train, v = 5)\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_recipe(rec1) %&gt;% \n  add_model(lm)\n\nFitting\n\nfit1 &lt;-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nPerformanze evaluieren\n\nwf1_performance &lt;-\n  collect_metrics(fit1)\nwf1_performance\n\n\n\n  \n\n\nwf_preds &lt;-\n  collect_predictions(fit1)\nwf_preds\n\n\n\n  \n\n\n\nVisualisierung\n\nwf_preds %&gt;% \n  group_by(id) %&gt;% \n  roc_curve(truth = class, .pred_other) %&gt;% \n  autoplot()\n\n\n\nconf_mat_resampled(fit1, tidy = FALSE) %&gt;% \n  autoplot(type = \"heatmap\")\n\n\n\n\nPuh, das ist ziemlich unterirdisch. Das Modell hat eine sehr geringe Sensitivität. Das bedeutet, dass es schlecht darin ist Hate Speech zu identifizieren. Das Modell arbeitet schlechter als ein zufälliger Klassifikator und sagt die falschen Klassen hervor. Ziel ist ein Modell aufzustellen, dessen ROC-Kurce nahe der y-Achse und an der oberen Grenze des Diagramms liegt. Dann hätte es eine hohe Sensitivität und Spezifität."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#vorhersage-mit-workflow-set",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#vorhersage-mit-workflow-set",
    "title": "Hate Speech Klassifikation",
    "section": "6.2 2.Vorhersage mit Workflow-Set",
    "text": "6.2 2.Vorhersage mit Workflow-Set\nModelle definieren\n\nif (!requireNamespace(\"doParallel\", quietly = TRUE)) {\n  install.packages(\"doParallel\")\n}\n\nlibrary(doParallel)\n\nLade nötiges Paket: foreach\n\n\n\nAttache Paket: 'foreach'\n\n\nDie folgenden Objekte sind maskiert von 'package:purrr':\n\n    accumulate, when\n\n\nLade nötiges Paket: iterators\n\n\nLade nötiges Paket: parallel\n\nregisterDoParallel(cores = detectCores())\n\n\n# Pakete laden\nlibrary(tidymodels)\nlibrary(textrecipes)\nlibrary(workflowsets)\nlibrary(syuzhet)      # Für get_sentiment()\n\n\n# Rezept vorbereiten\nrec2 &lt;-\n  recipe(class ~ ., data = d_train) %&gt;%\n  update_role(id, new_role = \"id\") %&gt;% \n  step_text_normalization(tweet) %&gt;%\n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\") %&gt;%\n  step_stem(tweet) %&gt;%\n  step_tfidf(tweet)  \n\n\n# Modelle definieren\nmodel_xgb &lt;- boost_tree(trees = 100) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nmodel_kknn &lt;- nearest_neighbor(neighbors = tune()) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nmodel_rf &lt;- rand_forest(trees = 100) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"classification\")\n\n# Workflow-Set erstellen\nwf_set &lt;- workflow_set(\n  preproc = list(text_prep = rec2),\n  models = list(xgb = model_xgb, kknn = model_kknn, rf = model_rf),\n  cross = TRUE\n)\n\n# Resampling definieren\nset.seed(123)\ncv_folds &lt;- vfold_cv(d_hate, v = 3, strata = class)\n\n# Tuning und Auswahl des besten Modells\nresults &lt;- wf_set %&gt;%\n  workflow_map(\n    fn = \"tune_grid\",\n    resamples = cv_folds,\n    grid = 5,\n    seed = 42,\n    metrics = metric_set(roc_auc),\n    verbose = TRUE, \n    control = control_resamples(save_pred = TRUE)\n  )\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 1 of 3 resampling: text_prep_xgb\n\n\n✔ 1 of 3 resampling: text_prep_xgb (8.2s)\n\n\ni 2 of 3 tuning:     text_prep_kknn\n\n\n✔ 2 of 3 tuning:     text_prep_kknn (4.4s)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 3 of 3 resampling: text_prep_rf\n\n\n✔ 3 of 3 resampling: text_prep_rf (7s)\n\ntune::autoplot(results) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nresults %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#visualisierung",
    "title": "Hate Speech Klassifikation",
    "section": "6.4 Visualisierung",
    "text": "6.4 Visualisierung\n\nlibrary(ggplot2)\n\n# Vorhersagen für den Testdatensatz machen, wenn noch nicht geschehen\npredictions &lt;- predict(fit_final, new_data = d_test, type = \"prob\")\n\n# Vorhersage-Verteilung visualisieren\npredictions %&gt;%\n  bind_cols(d_test %&gt;% select(class)) %&gt;%\n  ggplot(aes(x = `.pred_hate speech`, fill = class)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(x = \"Predicted Probability\", y = \"Count\", fill = \"Actual Class\")"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#vorhersage",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#vorhersage",
    "title": "Hate Speech Klassifikation",
    "section": "6.5 3.Vorhersage",
    "text": "6.5 3.Vorhersage"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_summary | default(““, true) }}\n\n\n\n\n\n{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ dataset_structure | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_structure | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "title": "1 Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_summary | default(““, true) }}\n\n\n\n\n\n{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}\n\n\n\n\nUse the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n\n{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}\n\n\n\n\n\n\n{{ model_examination | default(“[More Information Needed]”, true)}}\n\n\n\n\nCarbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Use the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_examination | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Carbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "href": "viren/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "title": "1 Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "viren/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "viren/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "IsabelleStokburger Blog",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "viren/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "href": "viren/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "title": "IsabelleStokburger Blog",
    "section": "",
    "text": "Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Python Markdown Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE PYTHON MARKDOWN PROJECT ‘’AS IS’’ AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANY CONTRIBUTORS TO THE PYTHON MARKDOWN PROJECT BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "viren/Lib/site-packages/numpy/random/LICENSE.html",
    "href": "viren/Lib/site-packages/numpy/random/LICENSE.html",
    "title": "1 NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\n1 NCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n2 3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n3 Components\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "viren/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "href": "viren/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "title": "1 libjpeg-turbo Licenses",
    "section": "",
    "text": "1 libjpeg-turbo Licenses\nlibjpeg-turbo is covered by three compatible BSD-style open source licenses:\n\nThe IJG (Independent JPEG Group) License, which is listed in README.ijg\nThis license applies to the libjpeg API library and associated programs (any code inherited from libjpeg, and any modifications to that code.)\nThe Modified (3-clause) BSD License, which is listed below\nThis license covers the TurboJPEG API library and associated programs, as well as the build system.\nThe zlib License\nThis license is a subset of the other two, and it covers the libjpeg-turbo SIMD extensions.\n\n\n\n2 Complying with the libjpeg-turbo Licenses\nThis section provides a roll-up of the libjpeg-turbo licensing terms, to the best of our understanding.\n\nIf you are distributing a modified version of the libjpeg-turbo source, then:\n\nYou cannot alter or remove any existing copyright or license notices from the source.\nOrigin\n\nClause 1 of the IJG License\nClause 1 of the Modified BSD License\nClauses 1 and 3 of the zlib License\n\nYou must add your own copyright notice to the header of each source file you modified, so others can tell that you modified that file (if there is not an existing copyright header in that file, then you can simply add a notice stating that you modified the file.)\nOrigin\n\nClause 1 of the IJG License\nClause 2 of the zlib License\n\nYou must include the IJG README file, and you must not alter any of the copyright or license text in that file.\nOrigin\n\nClause 1 of the IJG License\n\n\nIf you are distributing only libjpeg-turbo binaries without the source, or if you are distributing an application that statically links with libjpeg-turbo, then:\n\nYour product documentation must include a message stating:\nThis software is based in part on the work of the Independent JPEG Group.\nOrigin\n\nClause 2 of the IJG license\n\nIf your binary distribution includes or uses the TurboJPEG API, then your product documentation must include the text of the Modified BSD License (see below.)\nOrigin\n\nClause 2 of the Modified BSD License\n\n\nYou cannot use the name of the IJG or The libjpeg-turbo Project or the contributors thereof in advertising, publicity, etc.\nOrigin\n\nIJG License\nClause 3 of the Modified BSD License\n\nThe IJG and The libjpeg-turbo Project do not warrant libjpeg-turbo to be free of defects, nor do we accept any liability for undesirable consequences resulting from your use of the software.\nOrigin\n\nIJG License\nModified BSD License\nzlib License\n\n\n\n\n3 The Modified (3-clause) BSD License\nCopyright (C)2009-2022 D. R. Commander. All Rights Reserved. Copyright (C)2015 Viktor Szathmáry. All Rights Reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the libjpeg-turbo Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS”, AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n4 Why Three Licenses?\nThe zlib License could have been used instead of the Modified (3-clause) BSD License, and since the IJG License effectively subsumes the distribution conditions of the zlib License, this would have effectively placed libjpeg-turbo binary distributions under the IJG License. However, the IJG License specifically refers to the Independent JPEG Group and does not extend attribution and endorsement protections to other entities. Thus, it was desirable to choose a license that granted us the same protections for new code that were granted to the IJG for code derived from their software."
  },
  {
    "objectID": "viren/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "href": "viren/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "title": "IsabelleStokburger Blog",
    "section": "",
    "text": "Silk icon set 1.3 by Mark James mjames@gmail.com\nhttp://www.famfamfam.com/lab/icons/silk/\nLicense: CC-BY-2.5 or CC-BY-3.0"
  }
]