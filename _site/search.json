[
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Hate Speech Klassifikation Die Klassifikation von Hate Speech mit R in der Version 4.3.1 bietet eine effiziente Methode, um digitale Kommunikation auf toxische Inhalte zu analysieren. Das Stastikprogramm R eignet sich gut zur Verarbeitung natürlicher Sprache und maschinellen Lernen, um Hate Speech in Textdaten zu identifizieren und zu kategorisieren. Im Folgenden werden mit Hilfe verschiedener Textmining Methoden Tweets auf Hate Speech hin untersucht. Darüber hinaus werden prädiktive Modelle zur Klassifikation von Hate-Speech angewandt."
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#daten-laden",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#daten-laden",
    "title": "Hate Speech Klassifikation",
    "section": "1.1 Daten laden",
    "text": "1.1 Daten laden\n\nd_hate&lt;-\n  read.csv(datenpfad)\n\n\n1.1.1 Pakete laden\n\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(beepr)\nlibrary(discrim)\nlibrary(naivebayes)\nlibrary(textrecipes) \nlibrary(syuzhet)\nlibrary(tokenizers)  # Tokenisieren\nlibrary(tidytext)  # Textanalyse-Tools\nlibrary(SnowballC)  # Stemming\nlibrary(lsa)  # Stopwörter\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`\nlibrary(textclean)  # Emojis ersetzen\nlibrary(wordcloud)  # unübersichtlich, aber manche mögen es\nlibrary(ggplot2)\n\n\nd_hate1&lt;-\n  d_hate%&gt;%\n  select(tweet, class)%&gt;%\n  mutate(id = as.character(1:nrow(.)))\n\nd_hate1%&gt;%\n  count(class)\n\n\n\n  \n\n\n# Anzahl der Tweets pro Klasse zählen\nclass_counts &lt;- d_hate1 %&gt;%\n  count(class)\n\n# Histogramm erstellen\nggplot(class_counts, aes(x = class, y = n, fill = class)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  scale_fill_manual(values = c(\"hatespeech\" = \"yellow\", \"other\" = \"cyan\")) +\n  labs(title = \"Verteilung der Tweets nach Klasse\",\n       x = \"Klasse\",\n       y = \"Anzahl der Tweets\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nDas Balkendiagramm zeigt die Verteilung der Tweet in den zwei Klassen “hate_speech” und “other”. Rund 25% der Tweets sind im Datensatz als Hate Speech gelabelt.\n#Tweets aufbereiten\n\nd_hate1 &lt;- d_hate1 %&gt;%\n  mutate(tweet = str_remove_all(tweet, \"http[s]?://\\\\S+\")) %&gt;%\n  mutate(tweet = str_remove_all(tweet, \"\\\"\"))%&gt;%\n  mutate(tweet = tolower(tweet)) %&gt;%\n  mutate(tweet = gsub(\"[[:digit:]]\", \"\", tweet))\n\nIn diesem Schritt entferne ich alle URLs und Ziffern. Außerdem werden alle Buchstaben in der Tweet-Spalte zu Kleinbuchstaben umgewandelt. Das sorgt dafür, dass die Groß-/Kleinschreibung in der Textanalyse nicht berücksichtigt wird, was hilft, Duplikate zu vermeiden. Wenn es sich um deutsche Tweets handelt würde, sollte davon abgesehen werden, weil die verschiedenen Wortarten durch die Groß-/ Kleinschreibung gut unterschieden und als Textfeature zur Vorhersage nützlich wären.\n\nsum(is.na(d_hate1))\n\n[1] 0\n\n\nGut zu wissen, es gibt keine fehlenden Werte.\n\nvisdat::vis_dat(d_hate1, warn_large_data = FALSE)\n\n\n\n\nZudem gibt es keine fehlenden Werte und alle Variablen sind vom Typ ´character´. Das ist nur logisch, weil es sich um Text handelt und noch keine Tokenisierung durchgeführt wurde.\n##Aufteilung in Test- und Traindatensatz\n\nset.seed(123)\nd_split &lt;- initial_split(d_hate1, prop = .8, strata = class)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n###Seiten und Wörter zählen\n\nstr_count(d_train$tweet, pattern = \"\\\\w\") %&gt;% sum(na.rm = TRUE)\n\n[1] 295528\n\n\nDie zu untersuchende Zeile “Tweet” enthält 36.9224 Wörter. Das ist eine ausreichende Menge, um ein Modell sinnvoll trainieren zu können.\n\n\n\n\n\n\nNachstehend werden verschiedene Textmerkmale, auch als Textfeatures bezeichnet, untersucht. Durch das Analysieren der spezifischen Eigenschaften können Informationen über den Inhalt, die Struktur und die Bedeutung der Tweets gewonnen werden. Das hilft dabei, im späteren Verlauf Hassrede zu identifizieren. Anschließend werden die Tweets auf - Wortfrequenzen - Schimpfwörter - Emotionale Ladung untersucht.\n\n\n##Tokenisierung\n\n\n::: {.cell}\n\n\n{.r .cell-code} tokens &lt;- d_train %&gt;% unnest_tokens(word, tweet) :::\n\n\nDie Tokenisierung stellt einen wichtigen Schritt in der Textverarbeitung dar. Sie teilt den Text in sinnvolle Einheiten, sogenannte Tokens auf. Erst das ermöglicht weitere Verarbeitungsschritte, wie beispielsweise die Stoppwordentfernung.\n\n\n##Entfernen von Stopwords ###Stopwords für deutsch & englisch laden und kombinieren\n\n\n::: {.cell}\n\n\n{.r .cell-code} data(stopwords_de, package = \"lsa\") data(stopwords_en, package = \"lsa\") stopwords_en &lt;- tibble(word = stopwords_en) stopwords_de &lt;- tibble(word = stopwords_de) stopwords &lt;- bind_rows(stopwords_de, stopwords_en) :::\n\n\n::: {.cell}\n\n\n{.r .cell-code} tokens_filtered &lt;- tokens %&gt;% anti_join(stopwords, by = \"word\") :::\n\n\nDas Entfernen von stopwords hat den Vorteil, dass durch das Entfernen häufig vorkommende Wörter ohne semantische Bedeutung wie “a”, “and”, “so”… Rauschen im Text reduziert und die Analysequalität verbessert wird. Darüber hinaus verringert sich die zu verarbeitende Datenmenge.\n\n\n##Textlänge\n\n\n::: {.cell}\n\n\n{.r .cell-code} text_length &lt;- tokens_filtered %&gt;% group_by(id) %&gt;% summarise(word_count = n()) :::\n\n\nDie Textlänge kann Aufschluss über die Menge und Vielfalt der Informationen der Tweets geben. Gibt es möglicherweisee ungewöhnliche kurze oder lange Tweets, die genauer betrachtet werden sollten?\n\n\n##Worthäufigkeit\n\n\n::: {.cell}\n\n\n```{.r .cell-code} word_freq &lt;- tokens_filtered %&gt;% count(word, sort = TRUE)\n\n\nprint(head(text_length, n = 20)) # Die Textlänge der ersten 10 Tweets ```\n\n\n::: {.cell-output .cell-output-stdout}\n\n\n{.r .cell-code} print(head(word_freq, n = 20))   # Die 10 häufigsten Wörter\n\n\n::: {.cell-output .cell-output-stdout}\n\n\n{.r .cell-code} #Berechnung der Wortfrequenz word_freq_filtered &lt;- tokens_filtered %&gt;% count(word, sort = TRUE) %&gt;% top_n(20, n) :::\n\n\n###Visualisierung der Textlänge\n\n\n::: {.cell}\n\n\n```{.r .cell-code} text_length_filtered &lt;- tokens_filtered %&gt;% group_by(id) %&gt;% summarise(word_count = n())\n\n\n# Aktualisierte Visualisierung: Histogramm der Textlänge ohne Stoppwörter ggplot(text_length_filtered, aes(x = word_count)) + geom_histogram(binwidth = 1, fill = “blue”, color = “white”) + theme_minimal() + labs(title = “Histogramm der Textlänge ohne Stoppwörter”, x = “Anzahl der Wörter pro Tweet”, y = “Häufigkeit”) ```\n\n\n::: {.cell-output-display}  ::: :::\n\n\nDie Tweets bewegen sich alle in einem ähnlichen Rahmen und sind i.d.R zwischen drei und 13 Wörtern lang.\n\n\n##Visualisierung 1: Barplot der häufigsten Wörter ohne Stopwords\n\n\n::: {.cell}\n\n\n{.r .cell-code} ggplot(word_freq_filtered, aes(x = reorder(word, n), y = n)) + geom_col(fill = \"coral\", color = \"white\") + coord_flip() + theme_minimal() + labs(title = \"Top 20 häufigste Wörter\", x = \"\", y = \"Häufigkeit\")\n\n\n::: {.cell-output-display}  ::: :::\n\n\nAllein unter den 20 häufigsten Wörtern befinden sich bereits sieben Schimpfwörter. Die Genauigkeit der Grafik könnte noch verbessert werden, indem zum Beispiel ähnliche Ausdrücke wie “nigga” und “nigger” zusammengefasst werden, sodass der Barplot die kummulierte Häufigkeit anzeigt. Zusätzlich könnten weitere stopwords wie “it” durch die Hinzunahme eines weiteren Stopwords-Datensatzes entfernt werden.\n\n\n###Wörter ohne Aussagekraft aus tokenisierten Daten entfernen\n\n\n::: {.cell}\n\n\n{.r .cell-code} tokens_filtered &lt;- tokens_filtered %&gt;% filter(word != \"rt\") :::\n\n\nDa der Ausdruck “rt” keine Aussagekraft hat, wird er aus dem Datensatz entfernt.\n\n\n\n#Sentimentanalyse\n\nsenti_afinn &lt;- get_sentiments(\"afinn\") %&gt;% \n  mutate(neg_pos = case_when(value &gt; 0 ~ \"pos\",\n                             TRUE ~ \"neg\"))\n\n# Sentimentanalyse durchführen\ntokens_senti &lt;- tokens_filtered %&gt;%\n  inner_join(senti_afinn, by = \"word\")\n\nEin ebenfalls sehr wichtiges Werkzeug zur Datenanalyse ist die Sentimentanalyse. Mit ihr kann festgestellt werden, ob unsere Tweets bzw. Tokens eine negative oder positive Polung aufweisen, wobei Hate Speech mit einer negativen einhergeht. Die Textdaten werden so gefiltert, dass nur Wörter mit Sentimentwerten übrig bleiben.\n##Berechnung der durchschnittlichen Sentimentwerte pro Polarität und Tweet\n\ntokens_senti2 &lt;-\n  tokens_senti %&gt;% \n  group_by(id, neg_pos) %&gt;% \n  summarise(senti_avg = mean(value))\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\nhead(tokens_senti2)\n\n\n\n  \n\n\n\n##Zusammenführung der Sentimentwerte und Textlänge in den Hauptdatensatz\n\nsentis_wide &lt;-\n  tokens_senti2 %&gt;% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"senti_avg\")\n\nsentis_wide %&gt;% head()\n\n\n\n  \n\n\n#Zusammenführung mit Ursprungsdatensatz\nd_train2&lt;-\n  d_train%&gt;%\n  full_join(sentis_wide)\n\nJoining with `by = join_by(id)`\n\nd_train2 &lt;- d_train2 %&gt;%\n  left_join(text_length, by = \"id\")\n\n\nsenti_afinn%&gt;%\n  select(value, neg_pos)%&gt;%\n  describe_distribution()\n\n\n\n  \n\n\ntokens_senti %&gt;% \n  summarise(senti_sum = mean(value) %&gt;% round(2))\n\n\n\n  \n\n\n\nDas Sentimentlexikon ist insgesamt mit einem Wert von -0.59 leicht negativ. Die Tweets liegen mit -1.01 deutlich im negativen Bereich.\n##Visualisierung der Sentimentanalyse\n\nlibrary(ggplot2)\n\ntokens_senti %&gt;%\n  count(word, neg_pos, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  group_by(neg_pos) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(n, word, fill = neg_pos)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~neg_pos, scales = \"free_y\") +\n  labs(x = \"Häufigkeit\",\n       y = \"Wort\") +\n  theme_minimal()\n\n\n\n\nAuffällig ist, dass die negativ behafteten Wörter insgesamt deutlich häufiger vorkommen, als die positiven. Wenigsten wird der Ausdruck “love” häufiger verwendet als “hate.\n\n#Bigramme identifizieren Bigramme sind Paare von Wörtern, die häufig zusammen auftreten. Hierfür wird der Datensatz mit den Tweets verwenden, da Bigramme aus aufeinanderfolgenden Wortpaaren erstellt werden.\nDatensatz mit Tweets ohne stopwords erstellen\n\n# Benötigte Pakete laden\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stopwords)\n\n# Stopwörter für Deutsch holen\nstopwords_en &lt;- stopwords::stopwords(language = \"en\")\n\n\nbigrame2 &lt;- d_train %&gt;% dplyr::select(class, tweet) %&gt;% unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2)\n\nbigram_sep &lt;- bigrame2 %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\nbi_filt &lt;- bigram_sep %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\nbigram_unite&lt;-bi_filt%&gt;%\n  unite(bigram, word1, word2, sep = \" \")\n  \n# Häufigkeit der Bigramme zählen\nbigram_freq &lt;- bigram_unite %&gt;%\n  count(bigram, sort = TRUE)\n\n# Die 10 häufigsten Bigramme auswählen\ntop_bigrams &lt;- head(bigram_freq, 10)\n\n# Überprüfen der Ergebnisse\nprint(top_bigrams)\n\n          bigram  n\n1    white trash 49\n2    flappy bird 34\n3  charlie crist 29\n4  charlie sheen 24\n5  charlie brown 22\n6    derek jeter 21\n7          gt gt 21\n8     rt yankees 20\n9      ass nigga 18\n10 charlie baker 18\n\n\nVisualisierung der Bigramme\n\n# Visualisierung der Top-Bigramme\nggplot(top_bigrams, aes(x = reorder(bigram, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 häufigste Bigramme\",\n       x = \"Bigramme\",\n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n##Stemming\n\n# Stemming\ntokens_filtered$word &lt;- wordStem(tokens_filtered$word, language = \"en\")\n\n# Häufigkeiten zählen\nword_freq_stem &lt;- tokens_filtered %&gt;%\n  count(word, sort = TRUE)\n\n# Die 10 häufigsten Wörter auswählen\ntop_words_stem &lt;- head(word_freq_stem, 10)\n\n# Visualisierung\nggplot(top_words_stem, aes(x = reorder(word, n), y = n, fill = word)) +\n  geom_col() +\n  coord_flip() +  # Um die Wörter horizontal anzuzeigen\n  labs(title = \"Top 10 gestemmte Wörter\", x = \"Wörter\", y = \"Häufigkeit\") +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\n#Große Aussagekraft hat das nicht und neue Erkenntnisse kann ich daraus nicht ziehen. Zumindest ist es bunt und hebt die Stimmung für weiter Analysen\n\ncomms_bigram &lt;- \n  d_train2 %&gt;%\n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2) %&gt;%\n  filter(!is.na(bigram))\n\ncomms_bigram &lt;- comms_bigram %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")%&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\ncomms_bigram %&gt;%\n  unite(bigram, word1, word2, sep = \" \") %&gt;%\n  count(bigram, sort = TRUE) %&gt;%\n  slice_max(n, n = 10)%&gt;%\n  mutate(bigram = reorder(bigram, n)) %&gt;%\n  ggplot(aes(n, bigram)) +\n  geom_col(fill = \"#8175aa\") +\n  labs(title = \"Bigramme nach Häufigkeit\",\n       x = \"Häufigkeit\",\n       y = \"Bigram\") +\n  theme_minimal()\n\n\n\n\n\n#Schimpfwörter Tabelle stammt hier her: https://www.kaggle.com/datasets/johnzhangy/swear-words-dataset\n\nschimpf&lt;-\n  read.csv(\"~/Laptop/HS Ansbach/5. Semester/Data Science II/swearWords.csv\")\n\n# Zuerst die Schimpfwörter aus der Liste extrahieren\nswear_words_list &lt;- schimpf$swearwords\n\n# Filtern der Tokens nach Schimpfwörtern und Zählen ihrer Häufigkeit\nswear_words_freq &lt;- tokens_filtered %&gt;%\n  filter(word %in% swear_words_list) %&gt;%\n  count(word, sort = TRUE)\n\n# Die häufigsten Schimpfwörter auswählen\ntop_swear_words &lt;- head(swear_words_freq, 10)\n\nVisualisierung\n\n# Visualisierung der Top-Schimpfwörter\nggplot(top_swear_words, aes(x = reorder(word, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 häufigsten Schimpfwörter\",\n       x = \"Schimpfwörter\",\n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\nSchimpfwörter in Datensatz als zusätzlichen Prädiktor hinzufügen\n\n# Überprüfen, ob ein Tweet Schimpfwörter enthält\nd_train2 &lt;- d_train2 %&gt;%\n  mutate(swearwords = ifelse(str_detect(tolower(tweet), paste(schimpf$swearwords, collapse=\"|\")), \"ja\", \"nein\"))\n\n\n#Vorhersage\nNachdem ich mir mit der EDA einen Überblick über die Daten verschafft habe, werde ich jetzt verschiedene Algorithmen darauf trainieren, Hate Speech vorhersagen. Zu Beginn werde ich ein Rezept aufstellen, dass die Erkenntnisse meiner bisherigen Analyse aufgreift.\n#Vorhersage mit logistic regression\n#Rezept Das Rezept enthält die Textlänge, Sentimentwerte, Schimpfwörter und tfidf.\n\nlibrary(syuzhet)\n\nrec1 &lt;-\n  recipe(class ~ ., data = d_train) %&gt;%\n  update_role(id, new_role = \"id\") %&gt;% \n  step_text_normalization(tweet) %&gt;%\n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\") %&gt;%\n  step_stem(tweet) %&gt;%  \n  step_tfidf(tweet)\n \n  # step_mutate(senti = get_sentiment(tweet))\n\n#step_mutate(insult = get_sentiment(tweet,\n                                       #method = \"custom\",\n                                       #lexicon = insults)) %&gt;% \n\n\nbaked &lt;- rec1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = NULL)\nbaked\n\n\n\n  \n\n\n\nModell\n\nlm &lt;- naive_Bayes() %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"naivebayes\")\nlm\n\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\nKreuzvalidierung\n\nset.seed(42)\nfolds1 &lt;- vfold_cv(d_train, v = 5)\n\nWorkflow\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_recipe(rec1) %&gt;% \n  add_model(lm)\n\nFitting\n\nfit1 &lt;-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nPerformanze evaluieren\n\nwf1_performance &lt;-\n  collect_metrics(fit1)\nwf1_performance\n\n\n\n  \n\n\nwf_preds &lt;-\n  collect_predictions(fit1)\nwf_preds\n\n\n\n  \n\n\n\nVisualisierung\n\nwf_preds %&gt;% \n  group_by(id) %&gt;% \n  roc_curve(truth = class, .pred_other) %&gt;% \n  autoplot()\n\n\n\nconf_mat_resampled(fit1, tidy = FALSE) %&gt;% \n  autoplot(type = \"heatmap\")\n\n\n\n\nPuh, das ist ziemlich unterirdisch. Das Modell hat eine sehr geringe Sensitivität. Das bedeutet, dass es schlecht darin ist Hate Speech zu identifizieren. Das Modell arbeitet schlechter als ein zufälliger Klassifikator und sagt die falschen Klassen hervor. Ziel ist ein Modell aufzustellen, dessen ROC-Kurce nahe der y-Achse und an der oberen Grenze des Diagramms liegt. Dann hätte es eine hohe Sensitivität und Spezifität.\n##2.Vorhersage mit Workflow-Set Modelle definieren\n\nif (!requireNamespace(\"doParallel\", quietly = TRUE)) {\n  install.packages(\"doParallel\")\n}\n\nlibrary(doParallel)\n\nLade nötiges Paket: foreach\n\n\n\nAttache Paket: 'foreach'\n\n\nDie folgenden Objekte sind maskiert von 'package:purrr':\n\n    accumulate, when\n\n\nLade nötiges Paket: iterators\n\n\nLade nötiges Paket: parallel\n\nregisterDoParallel(cores = detectCores())\n\n\n##2.Vorhersage mit Workflow-Set\n\n# Pakete laden\nlibrary(tidymodels)\nlibrary(textrecipes)\nlibrary(workflowsets)\nlibrary(syuzhet)      # Für get_sentiment()\n\n\n# Rezept vorbereiten\nrec2 &lt;-\n  recipe(class ~ ., data = d_train) %&gt;%\n  update_role(id, new_role = \"id\") %&gt;% \n  step_text_normalization(tweet) %&gt;%\n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\") %&gt;%\n  step_stem(tweet) %&gt;%\n  step_tfidf(tweet)  \n\n\n# Modelle definieren\nmodel_xgb &lt;- boost_tree(trees = 100) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nmodel_kknn &lt;- nearest_neighbor(neighbors = tune()) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nmodel_rf &lt;- rand_forest(trees = 100) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"classification\")\n\n# Workflow-Set erstellen\nwf_set &lt;- workflow_set(\n  preproc = list(text_prep = rec2),\n  models = list(xgb = model_xgb, kknn = model_kknn, rf = model_rf),\n  cross = TRUE\n)\n\n# Resampling definieren\nset.seed(123)\ncv_folds &lt;- vfold_cv(d_hate, v = 3, strata = class)\n\n# Tuning und Auswahl des besten Modells\nresults &lt;- wf_set %&gt;%\n  workflow_map(\n    fn = \"tune_grid\",\n    resamples = cv_folds,\n    grid = 5,\n    seed = 42,\n    metrics = metric_set(roc_auc),\n    verbose = TRUE, \n    control = control_resamples(save_pred = TRUE)\n  )\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 1 of 3 resampling: text_prep_xgb\n\n\n✔ 1 of 3 resampling: text_prep_xgb (9s)\n\n\ni 2 of 3 tuning:     text_prep_kknn\n\n\n✔ 2 of 3 tuning:     text_prep_kknn (8s)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 3 of 3 resampling: text_prep_rf\n\n\n✔ 3 of 3 resampling: text_prep_rf (9.2s)\n\ntune::autoplot(results) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nresults %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)"
  },
  {
    "objectID": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#bestes-modell-extrahieren",
    "href": "posts/Prüfung/Pruefung_Isabelle_Stokburger.html#bestes-modell-extrahieren",
    "title": "Hate Speech Klassifikation",
    "section": "1.2 Bestes Modell extrahieren",
    "text": "1.2 Bestes Modell extrahieren\n\nbest_ml &lt;- \n  extract_workflow_set_result(results, \"text_prep_rf\") %&gt;% \n  select_best()\n\nbest_wf &lt;- \nwf_set %&gt;% \n  extract_workflow(\"text_prep_rf\")\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_ml)\n\nfit_final &lt;- fit(best_wf_finalized, data = d_train)\n\nVisualisierung\n\nlibrary(ggplot2)\n\n# Vorhersagen für den Testdatensatz machen, wenn noch nicht geschehen\npredictions &lt;- predict(fit_final, new_data = d_test, type = \"prob\")\n\n# Vorhersage-Verteilung visualisieren\npredictions %&gt;%\n  bind_cols(d_test %&gt;% select(class)) %&gt;%\n  ggplot(aes(x = `.pred_hate speech`, fill = class)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n  labs(x = \"Predicted Probability\", y = \"Count\", fill = \"Actual Class\")\n\n\n\n\n##3.Vorhersage #Prädiktives Modell für Textdaten von Hugging face\n\nlibrary(reticulate)\n\nWarning: Paket 'reticulate' wurde unter R Version 4.3.2 erstellt\n\n\n\nuse_virtualenv(\"~/Laptop/HS Ansbach/5. Semester/Data Science II/Prüfung/IsaBlogneu/viren\")\n\n\nfrom transformers import pipeline\n\nWARNING:tensorflow:From C:\\Users\\isast\\DOCUME~1\\Laptop\\HSANSB~1\\58A3C~1.SEM\\DATASC~1\\PRFUNG~1\\ISABLO~1\\viren\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nimport tensorflow as tf\n\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\n\ntweets &lt;- d_test$tweet\n\n\ntweets = r.tweets\nresults = classifier(tweets)\n\n\nresult &lt;- py$results\nlabels &lt;- lapply(result, function(element) element$label)\ntweets_hate &lt;- cbind(d_test, pred = unlist(labels))\ntweets_hate &lt;- tweets_hate %&gt;% \n  mutate(class = as.factor(class),\n         pred = case_when(pred == \"hate\" ~ \"hate speech\",\n            pred == \"nothate\" ~ \"other\"),\n         pred = as.factor(pred))\n\n\nmy_metrics2 &lt;- metric_set(accuracy, f_meas)\nmy_metrics2(tweets_hate,\n           truth = class,\n           estimate = pred)\n\n\n\n  \n\n\n\nDas Modell hat eine Genauigkeit von 91%. Das nenne ich traumhaft. Kein Vergleich zu den vorherigen Modellen."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IsabelleStokburger Blog",
    "section": "",
    "text": "Hate Speech Klassifikation\n\n\n\n\n\n\n\nTextanalyse\n\n\nTidymodels\n\n\nKlassifikation\n\n\nTransformers\n\n\nNeuronale Netze\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nIsabelle Stokburger\n\n\n\n\n\n\nNo matching items"
  }
]