---
title: "Hate Speech Klassifikation"
author: "Isabelle Stokburger"
date: "2024-02-09"
categories: [Textanalyse, Tidymodels, Klassifikation, Transformers, Neuronale Netze]
image: "Titelbild.webp"
---

# Hate Speech Klassifikation

![](images/hate%20speech.webp){width="524"}

Die Klassifikation von Hate Speech mit R in der Version 4.3.1 bietet eine effiziente Methode, um digitale Kommunikation auf toxische Inhalte zu analysieren. Das Stastikprogramm R eignet sich gut zur Verarbeitung natürlicher Sprache und maschinellen Lernen, um Hate Speech in Textdaten zu identifizieren und zu kategorisieren. Im Folgenden werden mit Hilfe verschiedener Textmining Methoden Tweets auf Hate Speech hin untersucht. Darüber hinaus werden prädiktive Modelle zur Klassifikation von Hate-Speech angewandt.

# Vorbereitung und EDA

Zu Beginn wird sich mittels der explorativen Datenanalyse ein Überblick über die Tweets verschafft. Das hilft ein besseres Verständnis für die Daten zu erlangen. Außerdem können so geeignete Textfeatures zur Vorhersage identifiziert werden, welche später im Rezept mitaufgenommen werden.

## Daten laden

```{r include=FALSE}
datenpfad<-"C:/Users/isast/Documents/Laptop/HS Ansbach/5. Semester/Data Science II/Prüfung/d_hate.csv"
```

```{r message=FALSE, warning=FALSE}
d_hate<-
  read.csv(datenpfad)
```

### Pakete laden

```{r output = FALSE}
library(tidyverse)
library(tictoc)
library(tidymodels)
library(tidytext)
library(beepr)
library(discrim)
library(naivebayes)
library(textrecipes) 
library(syuzhet)
library(tokenizers)  
library(tidytext)  
library(SnowballC)  
library(lsa)  
library(easystats)  
library(textclean)  
library(wordcloud)  
library(ggplot2)
library(textrecipes)
library(workflowsets)
library(sentimentr)
library(textdata)
library(tm)
library(stringr)
library(readr)
```

```{r}
d_hate1<-
  d_hate%>%
  select(tweet, class)%>%
  mutate(id = as.character(1:nrow(.)))

d_hate1%>%
  count(class)

# Anzahl der Tweets pro Klasse zählen
class_counts <- d_hate1 %>%
  count(class)

# Histogramm erstellen
ggplot(class_counts, aes(x = class, y = n, fill = class)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_manual(values = c("hatespeech" = "yellow", "other" = "cyan")) +
  labs(title = "Verteilung der Tweets nach Klasse",
       x = "Klasse",
       y = "Anzahl der Tweets") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Das Balkendiagramm zeigt die Verteilung der Tweet in den zwei Klassen "hate_speech" und "other". Rund 25% der Tweets sind im Datensatz als Hate Speech gelabelt.

# Tweets aufbereiten

```{r message=FALSE, warning=FALSE}
d_hate1 <- d_hate1 %>%
  mutate(tweet = str_remove_all(tweet, "http[s]?://\\S+")) %>%
  mutate(tweet = str_remove_all(tweet, "\""))%>%
  mutate(tweet = tolower(tweet)) %>%
  mutate(tweet = gsub("[[:digit:]]", "", tweet))
```

In diesem Schritt entferne ich alle URLs und Ziffern. Außerdem werden alle Buchstaben in der Tweet-Spalte zu Kleinbuchstaben umgewandelt. Das sorgt dafür, dass die Groß-/Kleinschreibung in der Textanalyse nicht berücksichtigt wird, was hilft, Duplikate zu vermeiden. Wenn es sich um deutsche Tweets handelt würde, sollte davon abgesehen werden, weil die verschiedenen Wortarten durch die Groß-/ Kleinschreibung gut unterschieden und als Textfeature zur Vorhersage nützlich wären. Alternativ übernimmt diese Aufgabe später die Funktion step_text_normalization(tweet) im Recipe.

```{r message=FALSE, warning=FALSE}
sum(is.na(d_hate1))
```

Gut zu wissen, es gibt keine fehlenden Werte.

```{r}
visdat::vis_dat(d_hate1, warn_large_data = FALSE)
```

Zudem gibt es keine fehlenden Werte und alle Variablen sind vom Typ ´character´. Das ist nur logisch, weil es sich um Text handelt und noch keine Tokenisierung durchgeführt wurde.

## Aufteilung in Test- und Traindatensatz

```{r message=FALSE, warning=FALSE}
set.seed(123)
d_split <- initial_split(d_hate1, prop = .8, strata = class)
d_train <- training(d_split)
d_test <- testing(d_split)
```

### Seiten und Wörter zählen

```{r}
str_count(d_train$tweet, pattern = "\\w") %>% sum(na.rm = TRUE)
```

Die zu untersuchende Zeile "Tweet" enthält XYXYXYX Wörter. Das ist eine ausreichende Menge, um ein Modell sinnvoll trainieren zu können.

------------------------------------------------------------------------

Nachstehend werden verschiedene Textmerkmale, auch als Textfeatures bezeichnet, untersucht. Durch das Analysieren der spezifischen Eigenschaften können Informationen über den Inhalt, die Struktur und die Bedeutung der Tweets gewonnen werden. Das hilft dabei, im späteren Verlauf Hassrede zu identifizieren. Anschließend werden die Tweets auf \* Wortfrequenzen \* Schimpfwörter \* Emotionale Ladung untersucht.

## Tokenisierung

```{r}
tokens <- d_train %>%
  unnest_tokens(word, tweet)
```

Die Tokenisierung stellt einen wichtigen Schritt in der Textverarbeitung dar. Sie teilt den Text in sinnvolle Einheiten, sogenannte Tokens auf. Erst das ermöglicht weitere Verarbeitungsschritte, wie beispielsweise die Stoppwordentfernung.

## Entfernen von Stopwords

### Stopwords laden

```{r}
data(stopwords_de, package = "lsa")
data(stopwords_en, package = "lsa")
stopwords_en <- tibble(word = stopwords_en)
stopwords_de <- tibble(word = stopwords_de)
stopwords <- bind_rows(stopwords_de, stopwords_en)
```

```{r}
tokens_filtered <- tokens %>%
  anti_join(stopwords, by = "word")
```

Das Entfernen von *stopwords* hat den Vorteil, dass durch das Entfernen häufig vorkommende Wörter ohne semantische Bedeutung wie "a", "and", "so"... Rauschen im Text reduziert und die Analysequalität verbessert wird. Darüber hinaus verringert sich die zu verarbeitende Datenmenge.

## Textlänge

```{r output = FALSE}
text_length <- tokens_filtered %>%
  group_by(id) %>%
  summarise(word_count = n())
```

Die Textlänge kann Aufschluss über die Menge und Vielfalt der Informationen der Tweets geben. Gibt es möglicherweisee ungewöhnliche kurze oder lange Tweets, die genauer betrachtet werden sollten?

## Worthäufigkeit

```{r output = FALSE}
word_freq <- tokens_filtered %>%
  count(word, sort = TRUE)

print(head(text_length, n = 20)) # Die Textlänge der ersten 10 Tweets
print(head(word_freq, n = 20))   # Die 10 häufigsten Wörter

#Berechnung der Wortfrequenz
word_freq_filtered <- tokens_filtered %>%
  count(word, sort = TRUE) %>%
  top_n(20, n)
```

### Visualisierung der Textlänge

```{r}
text_length_filtered <- tokens_filtered %>%
  group_by(id) %>%
  summarise(word_count = n())

# Aktualisierte Visualisierung: Histogramm der Textlänge ohne Stoppwörter
ggplot(text_length_filtered, aes(x = word_count)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "white") +
  theme_minimal() +
  labs(title = "Histogramm der Textlänge ohne Stoppwörter", x = "Anzahl der Wörter pro Tweet", y = "Häufigkeit")
```

Die Tweets bewegen sich alle in einem ähnlichen Rahmen und sind i.d.R zwischen drei und 13 Wörtern lang. Da es nicht viele Aussreißer gibt, werde ich es später im Rezept nicht beachten.

## Visualisierung 1: Barplot der häufigsten Wörter ohne Stopwords

```{r}
ggplot(word_freq_filtered, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "coral", color = "white") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 20 häufigste Wörter", x = "", y = "Häufigkeit")
```

Allein unter den 20 häufigsten Wörtern befinden sich bereits sieben Schimpfwörter. Die Genauigkeit der Grafik könnte noch verbessert werden, indem zum Beispiel ähnliche Ausdrücke wie "nigga" und "nigger" zusammengefasst werden, sodass der Barplot die kummulierte Häufigkeit anzeigt. Zusätzlich könnten weitere stopwords wie "it" durch die Hinzunahme eines weiteren Stopwords-Datensatzes entfernt werden.

### Wörter ohne Aussagekraft aus tokenisierten Daten entfernen

```{r}
tokens_filtered <- tokens_filtered %>%
  filter(word != "rt")
```

Da der Ausdruck "rt" keine Aussagekraft hat, wird er aus dem Datensatz entfernt.


------------------------------------------------------------------------

# Sentimentanalyse

```{r message=FALSE, warning=FALSE}
senti_afinn <- get_sentiments("afinn") %>% 
  mutate(neg_pos = case_when(value > 0 ~ "pos",
                             TRUE ~ "neg"))

# Sentimentanalyse durchführen
tokens_senti <- tokens_filtered %>%
  inner_join(senti_afinn, by = "word")
```

Ein ebenfalls sehr wichtiges Werkzeug zur Datenanalyse ist die Sentimentanalyse. Mit ihr kann festgestellt werden, ob unsere Tweets bzw. Tokens eine negative oder positive Polung aufweisen, wobei Hate Speech mit einer negativen einhergeht. Die Textdaten werden so gefiltert, dass nur Wörter mit Sentimentwerten übrig bleiben.

## Berechnung der durchschnittlichen Sentimentwerte pro Polarität und Tweet

```{r}
tokens_senti2 <-
  tokens_senti %>% 
  group_by(id, neg_pos) %>% 
  summarise(senti_avg = mean(value))

head(tokens_senti2)
```

## Zusammenführung der Sentimentwerte und Textlänge in den Hauptdatensatz

```{r output = FALSE}
sentis_wide <-
  tokens_senti2 %>% 
  pivot_wider(names_from = "neg_pos", values_from = "senti_avg")

sentis_wide %>% head()

#Zusammenführung mit Ursprungsdatensatz
d_train2<-
  d_train%>%
  full_join(sentis_wide)

d_train2 <- d_train2 %>%
  left_join(text_length, by = "id")
```

```{r}
senti_afinn%>%
  select(value, neg_pos)%>%
  describe_distribution()

tokens_senti %>% 
  summarise(senti_sum = mean(value) %>% round(2))
```

Das Sentimentlexikon ist insgesamt mit einem Wert von -0.59 leicht negativ. Die Tweets liegen mit -1.01 deutlich im negativen Bereich, was auf eine überwiegend negative Stimmung hindeutet. Das kann einmal auf das Thema der Diskussion zurückzuführen sein oder auch auf den gehäuften Gebrauch von Sarkasmus und Ironie.

## Visualisierung der Sentimentanalyse

```{r}
library(ggplot2)

tokens_senti %>%
  count(word, neg_pos, sort = TRUE) %>%
  ungroup() %>%
  group_by(neg_pos) %>%
  slice_max(n, n = 10)%>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = neg_pos)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~neg_pos, scales = "free_y") +
  labs(x = "Häufigkeit",
       y = "Wort") +
  theme_minimal()
```

Auffällig ist, dass die negativ behafteten Wörter insgesamt deutlich häufiger vorkommen, als die positiven. Das passt mit dem vorherigen Ergebnis zusammen. Wenigsten wird der Ausdruck "love" häufiger verwendet als "hate.

------------------------------------------------------------------------

# Bigramme identifizieren

Bigramme sind Paare von Wörtern, die häufig zusammen auftreten. Hierfür wird der Datensatz mit den Tweets verwenden, da Bigramme aus aufeinanderfolgenden Wortpaaren erstellt werden.

## Datensatz mit Tweets ohne stopwords erstellen

```{r output = FALSE}
# Benötigte Pakete laden
library(dplyr)
library(tidytext)
library(stopwords)

# Stopwörter für Deutsch holen
stopwords_en <- stopwords::stopwords(language = "en")


bigrame2 <- d_train %>% dplyr::select(class, tweet) %>% unnest_tokens(bigram, tweet, token = "ngrams", n = 2)

bigram_sep <- bigrame2 %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bi_filt <- bigram_sep %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_unite<-bi_filt%>%
  unite(bigram, word1, word2, sep = " ")
  
# Häufigkeit der Bigramme zählen
bigram_freq <- bigram_unite %>%
  count(bigram, sort = TRUE)

# Die 10 häufigsten Bigramme auswählen
top_bigrams <- head(bigram_freq, 10)

# Überprüfen der Ergebnisse
print(top_bigrams)

```

## Visualisierung der Bigramme

```{r}
# Visualisierung der Top-Bigramme
ggplot(top_bigrams, aes(x = reorder(bigram, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 häufigste Bigramme",
       x = "Bigramme",
       y = "Häufigkeit") +
  theme_minimal()
```

Anscheinend spielen Charlies eine große Rolle... besonders aussagekräftig ist das nicht. Hierfür wäre ein Bigram-Netz sinnvoll, um die Beziehungen der Wörter zueinander zu zeigen.

## Stemming

```{r}
# Stemming
tokens_filtered$word <- wordStem(tokens_filtered$word, language = "en")

# Häufigkeiten zählen
word_freq_stem <- tokens_filtered %>%
  count(word, sort = TRUE)

# Die 10 häufigsten Wörter auswählen
top_words_stem <- head(word_freq_stem, 10)

# Visualisierung
ggplot(top_words_stem, aes(x = reorder(word, n), y = n, fill = word)) +
  geom_col() +
  coord_flip() +  # Um die Wörter horizontal anzuzeigen
  labs(title = "Top 10 gestemmte Wörter", x = "Wörter", y = "Häufigkeit") +
  scale_fill_viridis_d() +
  theme_minimal()
```

Stemming habe ich durchgeführt, weil es die Anzahl der verschiedenen Wortformen reduziert, indem diese auf einen gemeinsamen Wortstamm zurückgeführt werden. Damit kann Rauschen reduziert werden und die Vergleichbarkeit erhöht. Ich hatte mir erhofft, häufig vorkommendene Wortgruppe zu extrahieren, Rauschen zu reduzieren und die Vergleichbarkeit der Wörter zu erhöhen. Leider hat der Output keine große Aussagekraft und nicht den gewünschten Effekt erzielt. Zumindest ist es bunt und hebt die Stimmung für weiter Analysen.

## Bigrame visualisieren

```{r}
comms_bigram <- 
  d_train2 %>%
  unnest_tokens(bigram, tweet, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram))

comms_bigram <- comms_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ")%>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

comms_bigram %>%
  unite(bigram, word1, word2, sep = " ") %>%
  count(bigram, sort = TRUE) %>%
  slice_max(n, n = 10)%>%
  mutate(bigram = reorder(bigram, n)) %>%
  ggplot(aes(n, bigram)) +
  geom_col(fill = "#8175aa") +
  labs(title = "Bigramme nach Häufigkeit",
       x = "Häufigkeit",
       y = "Bigram") +
  theme_minimal()
```

White Trash kommt mit Abstand am häufigsten vor. Das ist darauf zurückzuführen, dass trash sowohl in Verbindung mit "trash bins", als auch als Schimpfwort und Redewendung verwendet wird. Derek Jeter ist ein bekannter Baseballspieler, der lange Zeit bei den Yankees war. Deshalb kommen die beiden Ausdrücke ungefähr gleich oft vor. Bei Charlie Christ handelt es sich um den ehemaliger Gouverneur von Florida und bei Charlie Sheen um einen sehr bekannten amerikanischen Schauspieler. Charlie Brown ist ein Charakter von den Peanuts. Die Bigrame lassen vermuten, dass die Themenstreuung der Tweets sehr breit ist.

------------------------------------------------------------------------

# Schimpfwörter

Tabelle stammt hier her: https://www.kaggle.com/datasets/johnzhangy/swear-words-dataset

```{r}
schimpf<-
  read.csv("~/Laptop/HS Ansbach/5. Semester/Data Science II/swearWords.csv")

# Zuerst die Schimpfwörter aus der Liste extrahieren
swear_words_list <- schimpf$swearwords

# Filtern der Tokens nach Schimpfwörtern und Zählen ihrer Häufigkeit
swear_words_freq <- tokens_filtered %>%
  filter(word %in% swear_words_list) %>%
  count(word, sort = TRUE)

# Die häufigsten Schimpfwörter auswählen
top_swear_words <- head(swear_words_freq, 10)
```

Visualisierung

```{r}
# Visualisierung der Top-Schimpfwörter
ggplot(top_swear_words, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 häufigsten Schimpfwörter",
       x = "Schimpfwörter",
       y = "Häufigkeit") +
  theme_minimal()
```

Die Wörter "queer", "lmao" = "laug my ass off" und "faq" deuten auf eine eher jüngere Altersgruppe hin. Das am häufigsten verwendete Schimpfwort "bitch" kann als Spiegelung gesellschaftlicher Probleme gesehen werden, da der Gebrauch als ein Indikator für tiefer liegende gesellschaftliche Probleme wie Sexismus gedeutet werden kann. Eine alternative, schönere Erklärung könnte sein, dass "bitch" in der Popkultur, insbesondere in der Musik als Teil des künstlerischen Ausdrucks verwendet wird. In weiterführenden Analysen könnten mit Hilfe von Themenclustern die Zusammenhänge aufgebrochen werden.

Schimpfwörter in Datensatz als zusätzlichen Prädiktor hinzufügen

```{r}
# Überprüfen, ob ein Tweet Schimpfwörter enthält
d_train2 <- d_train2 %>%
  mutate(swearwords = ifelse(str_detect(tolower(tweet), paste(schimpf$swearwords, collapse="|")), "ja", "nein"))
```

Nachdem ich mir mit der EDA einen Überblick über die Daten verschafft habe, werde ich im Anschluss verschiedene Algorithmen darauf trainieren, Hate Speech vorhersagen. Zu Beginn werde ich ein Rezept aufstellen, dass die Erkenntnisse meiner bisherigen Analyse aufgreift.

# Tidymodels

## 1. Vorhersage mit logistic regression

Auf das Tunen wird bei der ersten Vorhersage verzichtet, um die Komplexität des Modells gering zu halten und somit Rechenzeit zu sparen.

## Rezept

Das Rezept enthält die Sentimentwerte, Schimpfwörter und tfidf. TFIDF wird zusätzlich mit aufgenommen, weil es nützlich zur Bewertung der Wichtigkeit von Begriffen ist.

```{r include=FALSE}
datenpfad2<- "~/Laptop/HS Ansbach/5. Semester/Data Science II/Data Science II/Insults_English.xlsx"
```

```{r}
library(readxl)
Insults_English <-
  read_excel(datenpfad2)
```

```{r}
Insults <-
  Insults_English %>%
  rename(word = abomination)

Insults$value <- 1
```

Rezept definieren

```{r}
library(syuzhet)

rec1 <-
  recipe(class ~ ., data = d_train) %>%
  update_role(id, new_role = "id") %>% 
  step_text_normalization(tweet) %>%
  step_mutate(schimpf_w = get_sentiment(tweet,
                                        method = "custom",
                                        lexicon = Insults)) %>%
  step_mutate(senti = get_sentiment(tweet, 
                                    method = "nrc",
                                    language = "english")) %>% 
  step_tokenize(tweet, token = "words") %>%
  step_tokenfilter(tweet, max_tokens = 1e2) %>%
  step_stopwords(tweet, language = "en", stopword_source = "snowball") %>%
  step_stem(tweet) %>%  
  step_tfidf(tweet)
```

Ich habe mich nun für einn anderes Schimpfwort-Wörterbuch entschieden. Das neue von stammt von https://www.insult.wiki/list-of-insults und hat zehnmal mehr Wörter im Vergleich zum "schimpf" Wörterbuch.

```{r}
baked <- rec1 %>% 
  prep() %>% 
  bake(new_data = NULL)
baked
```

Modell

```{r output = FALSE}
lm <- naive_Bayes() %>%
  set_mode("classification") %>%
  set_engine("naivebayes")
lm
```

Kreuzvalidierung

```{r output = FALSE}
set.seed(42)
folds1 <- vfold_cv(d_train, v = 5)
```

Workflow

```{r output = FALSE}
wf1 <-
  workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(lm)
```

Fitting

```{r}
fit1 <-
  fit_resamples(
    wf1,
    folds1,
    control = control_resamples(save_pred = TRUE)
  )
```

Performance evaluieren

```{r}
wf1_performance <-
  collect_metrics(fit1)
wf1_performance

wf_preds <-
  collect_predictions(fit1)
wf_preds
```

Visualisierung

```{r}
wf_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = class, .pred_other) %>% 
  autoplot()

conf_mat_resampled(fit1, tidy = FALSE) %>% 
  autoplot(type = "heatmap")
```

Puh, das ist ziemlich unterirdisch. Das Modell hat eine sehr geringe Sensitivität. Das bedeutet, dass es schlecht darin ist Hate Speech zu identifizieren und schlechter als ein zufälliger Klassifikator ist. Es sagt falsche Klassen vorher Ziel ist im weiteren Verlauf ein Modell aufzustellen, dessen ROC-Kurce nahe der y-Achse und an der oberen Grenze des Diagramms liegt. Dann hätte es eine hohe Sensitivität und Spezifität. Die Heatmap bestätigt das Ergebnis der ROC-Kurce.

## 2. Vorhersage mit Workflow-Set

```{r}
rec2<-
  recipe(class ~ ., data = d_train) %>%
  update_role(id, new_role = "id") %>% 
  step_text_normalization(tweet) %>%
  step_tokenize(tweet, token = "words") %>%
  step_tokenfilter(tweet, max_tokens = 1e2) %>%
  step_stopwords(tweet, language = "en", stopword_source = "snowball") %>%
  step_stem(tweet) %>%  
  step_tfidf(tweet)
```

Modelle definieren

```{r}
library(foreach)
library(purrr)

if (!requireNamespace("doParallel", quietly = TRUE)) {
  install.packages("doParallel")
}

library(doParallel)

registerDoParallel(cores = detectCores())
```

Modelle definieren

```{r}
model_xgb <- boost_tree(
  mtry = tune(), 
  trees = tune(), 
  tree_depth = tune()) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

model_kknn <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification")

model_rf <- rand_forest(trees = 100) %>%
  set_engine("ranger") %>%
  set_mode("classification")

# Workflow-Set erstellen
wf_set <- workflow_set(
  preproc = list(text_prep = rec2),
  models = list(xgb = model_xgb, kknn = model_kknn, rf = model_rf),
  cross = TRUE
)
```

Um Rechenzeit zu sparen, tune ich nur den XGBoost. Ich habe den XGBoost zum Tunen ausgesucht, weil dieser Algorithmen die meisten Tuningparamter besitzt und seine Leistung im Vergleich oft am besten abschneidet.

Resampling und Tuning

```{r}
# Resampling definieren
set.seed(123)
cv_folds <- vfold_cv(d_hate, v = 3, strata = class)

# Tuning und Auswahl des besten Modells
results <- wf_set %>%
  workflow_map(
    fn = "tune_grid",
    resamples = cv_folds,
    grid = 5,
    seed = 42,
    metrics = metric_set(roc_auc),
    verbose = TRUE, 
    control = control_resamples(save_pred = TRUE)
  )

tune::autoplot(results) +
  theme(legend.position = "bottom")
```

```{r}
results %>% 
  collect_metrics() %>% 
  arrange(-mean)
```

Obwohl ich den RandomForest nicht getuned habe, schneidet dieser am besten ab mit einem ROC von 0.87 und somit im Vergleich zum LM auch deutlich besser.

## Bestes Modell extrahieren

```{r}
best_ml <- 
  extract_workflow_set_result(results, "text_prep_rf") %>% 
  select_best()

best_wf <- 
wf_set %>% 
  extract_workflow("text_prep_rf")

best_wf_finalized <- 
  best_wf %>% 
  finalize_workflow(best_ml)

fit_final <- fit(best_wf_finalized, data = d_train)
```

## Visualisierung

```{r}
library(ggplot2)

# Vorhersagen für den Testdatensatz machen, wenn noch nicht geschehen
predictions <- predict(fit_final, new_data = d_test, type = "prob")

# Vorhersage-Verteilung visualisieren
predictions %>%
  bind_cols(d_test %>% select(class)) %>%
  ggplot(aes(x = `.pred_hate speech`, fill = class)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(x = "Predicted Probability", y = "Count", fill = "Actual Class")
```

Im Idealfall wäre links nur blaue Balken und rechts nur rote, sodass es keine Überschneidung gibt. Dann wäre die Vorhersage sehr genau und Hate Speech würde korrekt erkannt werden. Obwohl hier kein Sentiment- & Schimpfwortanalyse durcchgeführt wurde, schneidet der RandomForest Algorithmus besser ab, als die anderen drei.

# Hugging Face Modell

## 3. Vorhersage: Hugging face modell

Für die dritte Vorhersage nutze ich ein neuronales Netz, dass bereits trainiert wurde und von Hugging Face bezogen wird.

```{r}
library(reticulate)
```

```{r}
use_virtualenv("~/Laptop/HS Ansbach/5. Semester/Data Science II/Prüfung/IsaBlogneu/viren")
```

```{python}
from transformers import pipeline
import tensorflow as tf
```

```{python}
classifier = pipeline("text-classification", model="facebook/roberta-hate-speech-dynabench-r4-target")
```

```{r}
tweets <- d_test$tweet
```

```{python}
tweets = r.tweets
results = classifier(tweets)
```

```{r}
# Extraktion der 'name'-Werte aus der Liste 'py$results'
extracted_names <- lapply(py$results, function(item) item$label)

# Zusammenfügen der vorhergesagten Namen (vereinheitlicht) mit 'd_test' in eine neue Spalte 'prediction'
twitter_analysis <- cbind(d_test, prediction = unlist(extracted_names))

# Umwandlung der 'class'-Spalte in einen Faktor und Anpassung der 'prediction'-Spalte
twitter_analysis <- twitter_analysis %>%
  mutate(class = factor(class),
         prediction = ifelse(prediction == "hate", "hate speech", "other"),
         prediction = factor(prediction))

```

```{r}
my_metrics2 <- metric_set(accuracy, f_meas)
my_metrics2(twitter_analysis,
           truth = class,
           estimate = prediction)
```

Das Modell hat eine Genauigkeit von 91%. Das nenne ich traumhaft. Kein Vergleich zu den vorherigen Modellen.


## Nachtrag EDA: Sprache der Tweets

```{r message=FALSE, warning=FALSE}
py_install("pandas")
py_install("langdetect")
py_install("matplotlib")
```

```{python}
import pandas as pd

file_path = 'C:\\Users\\isast\\Documents\\Laptop\\HS Ansbach\\5. Semester\\Data Science II\\Prüfung\\d_hate.csv'

df = pd.read_csv(file_path)

print(df.head())

```

```{python}
from langdetect import detect
from collections import Counter
import matplotlib.pyplot as plt

# Funktion zur Erkennung der Sprache eines Tweets
def detect_language_from_tweet(tweet):
    try:
        # Erkenne die Sprache des Tweets
        return detect(tweet)
    except Exception as e:
        # Im Fehlerfall gib 'unbekannt' zurück
        return 'unbekannt'

# Spracherkennung auf jeden Tweet anwenden
df['detected_language'] = df['tweet'].apply(detect_language_from_tweet)

# Überprüfung der ersten paar Zeilen, um zu sehen, ob die Spracherkennung funktioniert hat
print(df[['tweet', 'detected_language']].head())

```


```{r}
df_r <- py$df

head(df_r)
```


```{r}
# Anzahl der Tweets pro Sprache
language_counts_df <- df_r %>%
  count(detected_language) %>%
  arrange(desc(n))

# Balkendiagramm der Sprachverteilung
ggplot(language_counts_df, aes(x = detected_language, y = n, fill = detected_language)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = 'Verteilung der erkannten Sprachen in Tweets',
       x = 'Sprache',
       y = 'Anzahl der Tweets') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


Gut zu wissen. Die Tweets sind fast ausschließlich in englisch. Wenige Ausnahmen, wie "af", dass in der Spracherkennung normalerweise für Afrikaans, eine Sprache, die hauptsächlich in Südafrika und Namibia gesprochen wird, können bei der verschwindend geringen Menge vernachlässigt werden und es kann auf ein englisches Schimpfwort- & Sentimentlexikon zurückgegriffen werden.


# Fazit

Die explorative Analyse der Daten half dabei, wichtige Merkmale in den Tweets zu erkennen mit dem Ziel Hassrede im zweiten Schritt der Modellierung präzise vorhersagen zu können. Dabei wurden hauptsächlich auf Beleidigungen und Sentimentwerte zurückgegriffen. Die Visualisierung häufig vorkommendender Begriffe hat zum besseren Verständnis der Daten beigetragen. Im zweiten Schritt der Modellierung wurde ein Mischung aus verschiedenen Trainingsmethoden und Deep Learning verwendet. Das Ziel war es Hate Speech im Datensatz, genauer den Tweets zu klassifzieren. Insgesamt haben die Deep Learning Modelle hierbei schlechter abgeschnitten.

# Session-Info

```{r}
sessionInfo()
```
