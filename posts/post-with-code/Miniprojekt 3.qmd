---
title: "Miniprojekt 3"
---
---
title: "Miniprojekt 2"
output: html_document
date: "2023-11-26"
---
#Pakete
```{r}
library(tictoc)
library(tidymodels)
library(tidytext)
library(beepr)
library(textrecipes) 
library(syuzhet)
data("schimpfwoerter", package = "pradadata")

schimpfwoerter$value <- 1
```

#Daten
```{r}
germeval_test<-
  read.csv("~/Laptop/HS Ansbach/5. Semester/Data Science II/Data Science II/10. Klassifikation von Hatespeech/germeval_test.csv")

germeval_train<-
  read.csv("~/Laptop/HS Ansbach/5. Semester/Data Science II/Data Science II/10. Klassifikation von Hatespeech/germeval_train.csv")

d_train<-
  germeval_train %>%
  select(id, text, c1, c2)

d_test<-
  germeval_test%>%
  select(id, text, c1, c2)
```

#Aufteilung in Test & Train-Datensatz
```{r}
daten_split<-initial_split(germeval_train)
d_train1 <-training(daten_split)
d_test1 <-testing(daten_split)
```


##1. Workflow fÃ¼r decision_tree
```{r}
mod1<-
  decision_tree(mode = "classification")

rec1<-
  recipe(c1 ~ ., data = d_train1)%>%
  update_role(id, new_role = "id")%>%
  step_tokenize(text)%>%
  step_tokenfilter(text, max_tokens = 1e3)%>%
  step_tfidf(text)%>%
  step_zv(all_predictors())%>%
  step_normalize(all_numeric_predictors())

wf1<-
  workflow()%>%
  add_model(mod1)%>%
  add_recipe(rec1)
```

#Fitting
```{r}
fit1<-
  fit(wf1, data = d_train1)

fit1
```

#Vorhersage
```{r}
preds1<-
  predict(fit1, new_data = d_test1)

d_test_pred1<-
  d_test1%>%
  bind_cols(preds1)%>%
  mutate(c1 = as.factor(c1))
```

#Metriken
```{r}
my_metrics1 <- metric_set(accuracy, f_meas)
my_metrics1 (d_test_pred1,
           truth = c1,
           estimate = .pred_class)

#decision_tree: accuarcy von 0.66
```
#Prep/ Bake
```{r}
tic()
rec1_prepped<-
  prep(rec1)
toc()

tic()
d_train_baked <- bake(rec1_prepped, new_data = NULL)
toc()

dim(d_train_baked) #5009 1002

d_train_baked%>%
  head()
```


##2. Workflow: random_forest
Weitere Vorverarbeitungsschritte: step_stopwords
```{r}
mod2 <-
  rand_forest(mode = "classification")

rec2 <-
  recipe(c1 ~ ., data = d_train) |> 
  update_role(id, new_role = "id")  |> 
  step_mutate(n_schimpf = get_sentiment(text, 
                                    method = "custom",
                                    lexicon = schimpfwoerter))%>%
  step_tokenize(text)%>%
  step_stopwords(text, language = "de", stopword_source = "snowball") %>%
  step_tokenfilter(text, max_tokens = 1e3)%>%
  step_tfidf(text)%>%
  step_zv(all_predictors())

wf2 <-
  workflow() %>% 
  add_model(mod2) %>% 
  add_recipe(rec2)
```

#Fitten
```{r}
tic()
fit2<-
  fit(wf2, data = d_train)
toc()
fit2
```

#Vorhersage
```{r}
pred2<-
  predict(fit1, new_data = germeval_test)

d_test2<-
  germeval_test%>%
  bind_cols(pred2)%>%
  mutate(c1 = as.factor(c1))
```

#Metriken
```{r}
my_metrics2 <- metric_set(accuracy, f_meas)
my_metrics2(d_test,
           truth = c1,
           estimate = .pred_class) #0.70
```





## 3. Workflow mit Wordvektoren
Textvektoren
```{r}
wiki_de_embeds_path <- "~/Laptop/HS Ansbach/5. Semester/Data Science II/dewiki_20180420_100d.txt/dewiki_20180420_100d.txt"


tic()
wiki_de_embeds <-
  data.table::fread(file = wiki_de_embeds_path,
                    sep = " ",
                    header = FALSE,
                    showProgress = FALSE)
toc()


names(wiki_de_embeds)[1] <- "word"

wiki <- as_tibble(wiki_de_embeds)


tic()
wiki_de_embeds <-
  data.table::fread(file = wiki_de_embeds_path,
                    sep = " ",
                    header = FALSE,
                    showProgress = FALSE)  # progressbar
toc()
```
